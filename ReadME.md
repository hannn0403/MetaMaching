# Meta-matching

## â—ï¸ Project Summary

---

1. **ì§„í–‰ê¸°ê°„:** 2023.07 ~ 2023.12
2. **ì—­í• :** ì£¼ì €ì, ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì„¤ê³„
3. **ê¸°ìˆ ìŠ¤íƒ:**  **`Python`**, **`PyTorch`**, **`Pandas`**, **`NumPy`**, **`Scikit-learn`**
4. **ê²°ê³¼ ë° ì„±ê³¼:** 
    - OHBM ë…¼ë¬¸ ê²Œì¬ [**[ğŸ“„]**](https://drive.google.com/file/d/1d8s6HwLw67PCEArFbB57kWfpDAohtU9B/view)
    - https://github.com/hannn0403/transformer-based-meta-matching-stacking
5. **ì£¼ìš”ë‚´ìš©:** ë³¸ ì—°êµ¬ëŠ” Human Connectome Projectì˜ 750ëª… ë‡Œ ì˜ìƒ ë°ì´í„°ì™€ 59ê°œì˜ ë¹„ì˜ìƒ í‘œí˜„í˜•ì„ í™œìš©í•˜ì—¬, ë‹¤ì–‘í•œ ì´ë¯¸ì§€ íŠ¹ì§• ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Basic DNNì„ í•™ìŠµí•œ í›„, 5ì¢… ì´ë¯¸ì§€ íŠ¹ì§• ë°ì´í„°ì—ì„œ ì˜ˆì¸¡í•œ 58ê°œì˜ ë¹„ì˜ìƒ í‘œí˜„í˜• ê°’ì„ í†µí•©í•œ multimodal feature matrixë¥¼ transformer encoderì— ì…ë ¥í•¨ìœ¼ë¡œì¨ ëª¨ë‹¬ë¦¬í‹° ê°„ ìƒí˜¸ê´€ê³„ë¥¼ self-attention ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” multimodal transformer stacking ê¸°ë²•ì„ ì œì•ˆí•˜ì˜€ë‹¤. ì´ ê¸°ë²•ì€ Train meta setê³¼ Test meta setì„ í™œìš©í•œ 50íšŒ ë°˜ë³µ ì‹¤í—˜ì—ì„œ, ë‹¨ì¼ ì´ë¯¸ì§€ íŠ¹ì§• ë°ì´í„°ë¥¼ ì´ìš©í•œ advanced stackingê³¼ stacking average ë°©ë²•ì— ë¹„í•´ í‰ê·  Pearsonâ€™s correlation ë° Coefficient of Determination(COD)ì´ ê°ê° 0.07, 0.12, 0.05, 0.08 ì”© í–¥ìƒëœ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ì˜ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìœµí•©í•˜ì—¬ ìœ ë™ì„± ì§€ëŠ¥ ì˜ˆì¸¡ì— ê¸°ì—¬í•¨ì„ ì…ì¦í•˜ì˜€ë‹¤.
---

# Transformer-based Meta-Matching Stacking

This repository contains the implementation of a multimodal transformer stacking framework for predicting fluid intelligence by integrating non-imaging phenotypes using self-attention (Meta-Matching stacking) on the Human Connectome Project (HCP) dataset.

## Features
- **Basic Predictors**: Train individual models (DNN, KRR) for each imaging modality feature set (sMRI, fMRI, dMRI).
- **Advanced Stacking**: Combine base predictor outputs across modalities to build a multimodal feature matrix.
- **Transformer Stacking**: Learn cross-modality relationships via a 9-layer Transformer encoder to predict fluid intelligence.
- **Modular Design**: Clean separation between data utilities (`functions.py`, `utils.py`), base learners (`basic_dnn.py`, `basic_krr.py`), stacking (`advanced_stacking.py`), and transformer workflow (`advanced_transformer.py`).

## Prerequisites
- Python 3.7+
- PyTorch
- NumPy, SciPy, pandas
- Scikit-learn
- tqdm

Install dependencies:
```bash
pip install torch numpy scipy pandas scikit-learn tqdm
```

## Repository Structure
```
transformer-based-meta-matching-stacking/
â”œâ”€â”€ figure/                      # Final figures (PNG) for publication
â”‚   â”œâ”€â”€ Final_figure_1.png
â”‚   â””â”€â”€ Final_figure_2.png
â”œâ”€â”€ model/                       # Core Python modules
â”‚   â”œâ”€â”€ basic_dnn.py             # Basic DNN predictor per modality
â”‚   â”œâ”€â”€ basic_krr.py             # Kernel Ridge Regression predictor per modality
â”‚   â”œâ”€â”€ advanced_stacking.py     # Script to perform multimodal stacking
â”‚   â”œâ”€â”€ advanced_transformer.py  # Transformer-based stacking workflow
â”‚   â”œâ”€â”€ advanced_finetuning.py   # Optional fine-tuning on small k-shot sets
â”‚   â”œâ”€â”€ CBIG_model_pytorch.py    # Reference CBIG model wrapper
â”‚   â”œâ”€â”€ functions.py             # Data loading & phenotype utilities
â”‚   â””â”€â”€ utils.py                 # Helper functions (metrics, I/O)
â””â”€â”€ README.md                    # This overview file (detailed usage below)
```

## Data Preparation
1. **Extract Features**: Preprocess raw MRI (sMRI, fMRI, dMRI) to feature matrices (e.g., MIND, functional connectivity, TBSS). Save each modality as CSV or NumPy array.
2. **Structure**: Create a `data/` directory:
   ```
   data/
     â”œâ”€â”€ sMRI.npy      # shape: [n_subjects, n_features]
     â”œâ”€â”€ fMRI.npy      # shape: [n_subjects, n_features]
     â””â”€â”€ dMRI.npy      # shape: [n_subjects, n_features]
   labels.csv         # columns: subject_id, fluid_intelligence, other phenotypes...
   ```
3. **Partition**: Split into meta-training and meta-testing sets (8:2 ratio). Within meta-testing, reserve k-shot and test subsets as described in the paper.

## Usage
All scripts in `model/` accept command-line arguments for input/output paths. Example workflows:

### 1. Train Base Predictors
```bash
python model/basic_dnn.py \
  --features data/sMRI.npy \
  --labels labels.csv \
  --output results/basic_dnn_sMRI

python model/basic_krr.py \
  --features data/fMRI.npy \
  --labels labels.csv \
  --output results/basic_krr_fMRI
```

### 2. Perform Advanced Stacking
Merge base predictions:
```bash
python model/advanced_stacking.py \
  --pred_dirs results/basic_dnn_sMRI,results/basic_krr_fMRI,results/basic_dnn_dMRI \
  --labels labels.csv \
  --output results/stacking
```
This generates a multimodal feature matrix for the Transformer.

### 3. Train Transformer Stacking Model
```bash
python model/advanced_transformer.py \
  --stacked_features results/stacking/features.npy \
  --labels results/stacking/labels.npy \
  --output results/transformer_stacking \
  --num_layers 9 \
  --hidden_dim 256 \
  --epochs 100 \
  --batch_size 32 \
  --learning_rate 1e-4
```

### 4. Evaluate & Visualize
- Final prediction metrics (Pearsonâ€™s r, COD) will be saved to `results/transformer_stacking/metrics.csv`.
- Use `figure/Final_figure_1.png` and `figure/Final_figure_2.png` for publication-quality plots.
---
